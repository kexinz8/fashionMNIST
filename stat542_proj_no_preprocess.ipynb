{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a1d974f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ae9c97b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import fashion_mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcd100f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb7a6af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data\n",
    "(train_data, train_labels), (test_data, test_labels) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6125abcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = train_data.reshape(train_data.shape[0], -1).astype('float32')\n",
    "test_x = test_data.reshape(test_data.shape[0], -1).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e20b359",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b89cfd2d",
   "metadata": {},
   "source": [
    "# LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "38a2fbf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "542b30b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_model = LGBMClassifier(objective='multiclass',path_smooth = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b4059e5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asus\\anaconda3\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(objective='multiclass', path_smooth=0.2)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgb_model.fit(train_x,train_labels,categorical_feature=[0,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "256ee1d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.86      0.85      1000\n",
      "           1       1.00      0.97      0.98      1000\n",
      "           2       0.80      0.83      0.81      1000\n",
      "           3       0.89      0.90      0.90      1000\n",
      "           4       0.80      0.83      0.82      1000\n",
      "           5       0.99      0.97      0.98      1000\n",
      "           6       0.72      0.66      0.69      1000\n",
      "           7       0.95      0.97      0.96      1000\n",
      "           8       0.98      0.97      0.98      1000\n",
      "           9       0.97      0.96      0.96      1000\n",
      "\n",
      "    accuracy                           0.89     10000\n",
      "   macro avg       0.89      0.89      0.89     10000\n",
      "weighted avg       0.89      0.89      0.89     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "expected_y  = test_labels\n",
    "predicted_y = lgb_model.predict(test_x)\n",
    "lightGBM_pred_y = predicted_y\n",
    "print(metrics.classification_report(expected_y, predicted_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa60f447",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "98c79bed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asus\\anaconda3\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n",
      "C:\\Users\\asus\\anaconda3\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n",
      "C:\\Users\\asus\\anaconda3\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n",
      "C:\\Users\\asus\\anaconda3\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n",
      "C:\\Users\\asus\\anaconda3\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n",
      "C:\\Users\\asus\\anaconda3\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n",
      "C:\\Users\\asus\\anaconda3\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n",
      "C:\\Users\\asus\\anaconda3\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n",
      "C:\\Users\\asus\\anaconda3\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n",
      "C:\\Users\\asus\\anaconda3\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.0939, 0.0947, 0.0945, 0.0936, 0.0943, 0.0927, 0.0952, 0.094, 0.0941, 0.0948]"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dont run this part, i'm still tuning\n",
    "err_list = []\n",
    "for i in np.arange(0.0, 1.0, 0.1):\n",
    "    model = LGBMClassifier(objective='multiclass',path_smooth = i)\n",
    "    model.fit(X_train,y_train,categorical_feature=[0,3])\n",
    "    predictions = model.predict(X_test)\n",
    "    error = sum(predictions!=y_test)/len(y_test)\n",
    "    err_list.append(error)\n",
    "err_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53eb347d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "23429c60",
   "metadata": {},
   "source": [
    "# LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "abfbf016",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "8a6b7f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "lda = LDA(n_components=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "f4823097",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.78      0.79      1000\n",
      "           1       1.00      0.93      0.96      1000\n",
      "           2       0.70      0.68      0.69      1000\n",
      "           3       0.80      0.85      0.82      1000\n",
      "           4       0.70      0.74      0.72      1000\n",
      "           5       0.89      0.89      0.89      1000\n",
      "           6       0.54      0.56      0.55      1000\n",
      "           7       0.88      0.89      0.89      1000\n",
      "           8       0.94      0.92      0.93      1000\n",
      "           9       0.91      0.91      0.91      1000\n",
      "\n",
      "    accuracy                           0.82     10000\n",
      "   macro avg       0.82      0.82      0.82     10000\n",
      "weighted avg       0.82      0.82      0.82     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "expected_y  = test_labels\n",
    "lda_model = lda.fit(train_x, train_labels)\n",
    "predicted_y = lda_model.predict(test_x)\n",
    "lda_pred_y = predicted_y\n",
    "print(metrics.classification_report(expected_y, predicted_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "435896e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.808533</td>\n",
       "      <td>0.7770</td>\n",
       "      <td>0.792453</td>\n",
       "      <td>1000.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.996795</td>\n",
       "      <td>0.9330</td>\n",
       "      <td>0.963843</td>\n",
       "      <td>1000.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.703093</td>\n",
       "      <td>0.6820</td>\n",
       "      <td>0.692386</td>\n",
       "      <td>1000.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.801136</td>\n",
       "      <td>0.8460</td>\n",
       "      <td>0.822957</td>\n",
       "      <td>1000.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.700943</td>\n",
       "      <td>0.7430</td>\n",
       "      <td>0.721359</td>\n",
       "      <td>1000.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.886454</td>\n",
       "      <td>0.8900</td>\n",
       "      <td>0.888224</td>\n",
       "      <td>1000.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.544922</td>\n",
       "      <td>0.5580</td>\n",
       "      <td>0.551383</td>\n",
       "      <td>1000.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.883284</td>\n",
       "      <td>0.8930</td>\n",
       "      <td>0.888115</td>\n",
       "      <td>1000.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.935910</td>\n",
       "      <td>0.9200</td>\n",
       "      <td>0.927887</td>\n",
       "      <td>1000.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.913568</td>\n",
       "      <td>0.9090</td>\n",
       "      <td>0.911278</td>\n",
       "      <td>1000.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.815100</td>\n",
       "      <td>0.8151</td>\n",
       "      <td>0.815100</td>\n",
       "      <td>0.8151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.817464</td>\n",
       "      <td>0.8151</td>\n",
       "      <td>0.815989</td>\n",
       "      <td>10000.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.817464</td>\n",
       "      <td>0.8151</td>\n",
       "      <td>0.815989</td>\n",
       "      <td>10000.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision  recall  f1-score     support\n",
       "0              0.808533  0.7770  0.792453   1000.0000\n",
       "1              0.996795  0.9330  0.963843   1000.0000\n",
       "2              0.703093  0.6820  0.692386   1000.0000\n",
       "3              0.801136  0.8460  0.822957   1000.0000\n",
       "4              0.700943  0.7430  0.721359   1000.0000\n",
       "5              0.886454  0.8900  0.888224   1000.0000\n",
       "6              0.544922  0.5580  0.551383   1000.0000\n",
       "7              0.883284  0.8930  0.888115   1000.0000\n",
       "8              0.935910  0.9200  0.927887   1000.0000\n",
       "9              0.913568  0.9090  0.911278   1000.0000\n",
       "accuracy       0.815100  0.8151  0.815100      0.8151\n",
       "macro avg      0.817464  0.8151  0.815989  10000.0000\n",
       "weighted avg   0.817464  0.8151  0.815989  10000.0000"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report = metrics.classification_report(expected_y, predicted_y, output_dict=True)\n",
    "pd.DataFrame(report).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb5448f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "87067edd",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "416cccde",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "import sklearn.model_selection as model_selection\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "184de6fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Ploynomial kernel \n",
    "svmpoly = svm.SVC(kernel='poly', degree=3, C=1).fit(train_x, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "5196b9e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.84      0.81      1000\n",
      "           1       0.99      0.95      0.97      1000\n",
      "           2       0.80      0.78      0.79      1000\n",
      "           3       0.88      0.86      0.87      1000\n",
      "           4       0.83      0.76      0.79      1000\n",
      "           5       0.84      0.96      0.89      1000\n",
      "           6       0.66      0.69      0.68      1000\n",
      "           7       0.94      0.91      0.92      1000\n",
      "           8       0.97      0.94      0.95      1000\n",
      "           9       0.96      0.94      0.95      1000\n",
      "\n",
      "    accuracy                           0.86     10000\n",
      "   macro avg       0.87      0.86      0.86     10000\n",
      "weighted avg       0.87      0.86      0.86     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "expected_y  = test_labels\n",
    "predicted_y = svmpoly.predict(test_x)\n",
    "SVM_pred_y = predicted_y\n",
    "print(metrics.classification_report(expected_y, predicted_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "c8926f00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.790019</td>\n",
       "      <td>0.839</td>\n",
       "      <td>0.813773</td>\n",
       "      <td>1000.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.991693</td>\n",
       "      <td>0.955</td>\n",
       "      <td>0.973001</td>\n",
       "      <td>1000.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.804145</td>\n",
       "      <td>0.776</td>\n",
       "      <td>0.789822</td>\n",
       "      <td>1000.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.878695</td>\n",
       "      <td>0.862</td>\n",
       "      <td>0.870268</td>\n",
       "      <td>1000.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.825708</td>\n",
       "      <td>0.758</td>\n",
       "      <td>0.790407</td>\n",
       "      <td>1000.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.835366</td>\n",
       "      <td>0.959</td>\n",
       "      <td>0.892924</td>\n",
       "      <td>1000.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.662500</td>\n",
       "      <td>0.689</td>\n",
       "      <td>0.675490</td>\n",
       "      <td>1000.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.936410</td>\n",
       "      <td>0.913</td>\n",
       "      <td>0.924557</td>\n",
       "      <td>1000.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.966084</td>\n",
       "      <td>0.940</td>\n",
       "      <td>0.952864</td>\n",
       "      <td>1000.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.963077</td>\n",
       "      <td>0.939</td>\n",
       "      <td>0.950886</td>\n",
       "      <td>1000.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.863000</td>\n",
       "      <td>0.863</td>\n",
       "      <td>0.863000</td>\n",
       "      <td>0.863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.865370</td>\n",
       "      <td>0.863</td>\n",
       "      <td>0.863399</td>\n",
       "      <td>10000.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.865370</td>\n",
       "      <td>0.863</td>\n",
       "      <td>0.863399</td>\n",
       "      <td>10000.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision  recall  f1-score    support\n",
       "0              0.790019   0.839  0.813773   1000.000\n",
       "1              0.991693   0.955  0.973001   1000.000\n",
       "2              0.804145   0.776  0.789822   1000.000\n",
       "3              0.878695   0.862  0.870268   1000.000\n",
       "4              0.825708   0.758  0.790407   1000.000\n",
       "5              0.835366   0.959  0.892924   1000.000\n",
       "6              0.662500   0.689  0.675490   1000.000\n",
       "7              0.936410   0.913  0.924557   1000.000\n",
       "8              0.966084   0.940  0.952864   1000.000\n",
       "9              0.963077   0.939  0.950886   1000.000\n",
       "accuracy       0.863000   0.863  0.863000      0.863\n",
       "macro avg      0.865370   0.863  0.863399  10000.000\n",
       "weighted avg   0.865370   0.863  0.863399  10000.000"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report = metrics.classification_report(expected_y, predicted_y, output_dict=True)\n",
    "pd.DataFrame(report).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c1a93d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7adf3003",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to get the precision dictionary\n",
    "out = {}\n",
    "for i in range(0,10):\n",
    "    out.update({i:round(report[str(i)]['precision'],2)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e425a2ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "6413f7b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create df of y_pred of test set for each model\n",
    "y_pred_test = pd.concat([pd.DataFrame(lightGBM_pred_y, columns = ['LightGBM']),\n",
    "           pd.DataFrame(lda_pred_y, columns = ['LDA']), \n",
    "           pd.DataFrame(SVM_pred_y, columns = ['SVM'])],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "0500a56e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test.to_csv('y_pred_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b4de77",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
